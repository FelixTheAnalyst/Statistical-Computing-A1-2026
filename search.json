[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STA Honours 2026 – Statistical Computing",
    "section": "",
    "text": "This website contains my submission for Statistical Computing – Assignment 1.\n\n\n\nPrac 1\nDay 3 (Questions 4 and 5)\nPrac 4\n\nAll work is rendered using Quarto and the source code is available on GitHub."
  },
  {
    "objectID": "index.html#assignment-1",
    "href": "index.html#assignment-1",
    "title": "STA Honours 2026 – Statistical Computing",
    "section": "",
    "text": "This website contains my submission for Statistical Computing – Assignment 1.\n\n\n\nPrac 1\nDay 3 (Questions 4 and 5)\nPrac 4\n\nAll work is rendered using Quarto and the source code is available on GitHub."
  },
  {
    "objectID": "Prac4.html",
    "href": "Prac4.html",
    "title": "Practical 4",
    "section": "",
    "text": "1 Questions\nUse tidyr and dplyr wherever appropriate below. In other words, do not use base R functions unless necessary or otherwise instructed.\nUsing the flights dataset:\n\nlibrary(tidyr)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(nycflights13)\n\nWarning: package 'nycflights13' was built under R version 4.4.3\n\n\n\nDisplay the flights dataset in an alternative format to simply printing it (i.e. running flights).\n\n\nflights %&gt;% glimpse() # gives a transposed, compact view\n\nRows: 336,776\nColumns: 19\n$ year           &lt;int&gt; 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2…\n$ month          &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ day            &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ dep_time       &lt;int&gt; 517, 533, 542, 544, 554, 554, 555, 557, 557, 558, 558, …\n$ sched_dep_time &lt;int&gt; 515, 529, 540, 545, 600, 558, 600, 600, 600, 600, 600, …\n$ dep_delay      &lt;dbl&gt; 2, 4, 2, -1, -6, -4, -5, -3, -3, -2, -2, -2, -2, -2, -1…\n$ arr_time       &lt;int&gt; 830, 850, 923, 1004, 812, 740, 913, 709, 838, 753, 849,…\n$ sched_arr_time &lt;int&gt; 819, 830, 850, 1022, 837, 728, 854, 723, 846, 745, 851,…\n$ arr_delay      &lt;dbl&gt; 11, 20, 33, -18, -25, 12, 19, -14, -8, 8, -2, -3, 7, -1…\n$ carrier        &lt;chr&gt; \"UA\", \"UA\", \"AA\", \"B6\", \"DL\", \"UA\", \"B6\", \"EV\", \"B6\", \"…\n$ flight         &lt;int&gt; 1545, 1714, 1141, 725, 461, 1696, 507, 5708, 79, 301, 4…\n$ tailnum        &lt;chr&gt; \"N14228\", \"N24211\", \"N619AA\", \"N804JB\", \"N668DN\", \"N394…\n$ origin         &lt;chr&gt; \"EWR\", \"LGA\", \"JFK\", \"JFK\", \"LGA\", \"EWR\", \"EWR\", \"LGA\",…\n$ dest           &lt;chr&gt; \"IAH\", \"IAH\", \"MIA\", \"BQN\", \"ATL\", \"ORD\", \"FLL\", \"IAD\",…\n$ air_time       &lt;dbl&gt; 227, 227, 160, 183, 116, 150, 158, 53, 140, 138, 149, 1…\n$ distance       &lt;dbl&gt; 1400, 1416, 1089, 1576, 762, 719, 1065, 229, 944, 733, …\n$ hour           &lt;dbl&gt; 5, 5, 5, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6…\n$ minute         &lt;dbl&gt; 15, 29, 40, 45, 0, 58, 0, 0, 0, 0, 0, 0, 0, 0, 0, 59, 0…\n$ time_hour      &lt;dttm&gt; 2013-01-01 05:00:00, 2013-01-01 05:00:00, 2013-01-01 0…\n\n\n\nRewrite this code using dplyr and the pipe:\n\nBad code (given)\n\nflight1 &lt;- flights[flights$month == 1, ]\ncarrier_vec &lt;- unique(flight1$carrier)\ncarrier_dist_vec_mean &lt;- numeric(length(carrier_vec))\ncarrier_dist_vec_sd &lt;- numeric(length(carrier_vec))\nfor (i in seq_along(carrier_vec)) {\n  carrier_dist_vec_mean[i] &lt;- mean(\n    flight1$distance[flight1$carrier == carrier_vec[i]]\n   )\n  carrier_dist_vec_sd[i] &lt;- sd(\n    flight1$distance[flight1$carrier == carrier_vec[i]]\n  )\n}\ndist_tbl &lt;- tibble(\n  carrier = carrier_vec,\n  mean_distance = carrier_dist_vec_mean,\n  sd_distance = carrier_dist_vec_sd\n)\ndist_tbl[order(dist_tbl$mean_distance), ]\n\n# A tibble: 16 × 3\n   carrier mean_distance sd_distance\n   &lt;chr&gt;           &lt;dbl&gt;       &lt;dbl&gt;\n 1 YV               229          0  \n 2 9E               476.       334. \n 3 EV               522.       294. \n 4 US               536.       553. \n 5 MQ               566.       223. \n 6 FL               691.       142. \n 7 OO               733         NA  \n 8 WN               942.       496. \n 9 B6              1062.       681. \n10 DL              1220.       644. \n11 AA              1350.       626. \n12 UA              1462.       778. \n13 F9              1620          0  \n14 AS              2402          0  \n15 VX              2495.        98.2\n16 HA              4983          0  \n\n\nClean code (using dplyr)\n\ndist_tbl &lt;- flights %&gt;%\n  filter(month == 1) %&gt;%                 # keep January flights\n  group_by(carrier) %&gt;%                  # group by carrier\n  summarise(\n    mean_distance = mean(distance, na.rm = TRUE),\n    sd_distance   = sd(distance, na.rm = TRUE),\n    n = n()                               # keep count for diagnostics\n  ) %&gt;%\n  arrange(mean_distance)                  # sort mean distance\n\ndist_tbl\n\n# A tibble: 16 × 4\n   carrier mean_distance sd_distance     n\n   &lt;chr&gt;           &lt;dbl&gt;       &lt;dbl&gt; &lt;int&gt;\n 1 YV               229          0      46\n 2 9E               476.       334.   1573\n 3 EV               522.       294.   4171\n 4 US               536.       553.   1602\n 5 MQ               566.       223.   2271\n 6 FL               691.       142.    328\n 7 OO               733         NA       1\n 8 WN               942.       496.    996\n 9 B6              1062.       681.   4427\n10 DL              1220.       644.   3690\n11 AA              1350.       626.   2794\n12 UA              1462.       778.   4637\n13 F9              1620          0      59\n14 AS              2402          0      62\n15 VX              2495.        98.2   316\n16 HA              4983          0      31\n\n\n\nExplain why the standard deviation is NA for one carrier, and why it is 0 for others. Demonstrate your answer using code.\n\nAnswer:\nThe possible reasons are as follows:\n\nsd(x) is NA if there is only once observation (n=1)\nsd(x) is 0 if there is multiple observations but all values are identical\n\nA demonstration is provided below.\n\ndist_tbl %&gt;%\n  filter(is.na(sd_distance) | sd_distance == 0) # check nas\n\n# A tibble: 5 × 4\n  carrier mean_distance sd_distance     n\n  &lt;chr&gt;           &lt;dbl&gt;       &lt;dbl&gt; &lt;int&gt;\n1 YV                229           0    46\n2 OO                733          NA     1\n3 F9               1620           0    59\n4 AS               2402           0    62\n5 HA               4983           0    31\n\nflights %&gt;%\n  filter(month == 1) %&gt;% \n  count(carrier) %&gt;%\n  filter(n &lt;= 2) # check multiple observations\n\n# A tibble: 1 × 2\n  carrier     n\n  &lt;chr&gt;   &lt;int&gt;\n1 OO          1\n\n\n\nUsing tidyr and dplyr where appropriate, construct a dataframe where the carriers are along the columns, and the rows are the average departure delay (dep_delay) flown by each carrier (carrier) in each month.\n\n\ndep_delay_wide &lt;- flights %&gt;%\n  group_by(month, carrier) %&gt;%                      # month–carrier pairs\n  summarise(\n    avg_dep_delay = mean(dep_delay, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %&gt;%\n  pivot_wider( # resphapes long -&gt; wide\n    names_from = carrier,          # defines new col names                  # carriers → columns\n    values_from = avg_dep_delay    # defines cell values\n  )\n\ndep_delay_wide\n\n# A tibble: 12 × 17\n   month  `9E`    AA     AS    B6    DL    EV    F9    FL    HA    MQ    OO\n   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1     1 16.9   6.93  7.35   9.49  3.85 24.2  10     1.97 54.4   6.49 67   \n 2     2 16.5   8.28  0.722 13.8   5.54 21.5  29.8   5.18 17.4   8.09 NA   \n 3     3 13.4   8.70  8.42  14.2   9.93 26.2  16.8  17.3   1.16  7.19 NA   \n 4     4 13.6  11.7  11.3   15.2   8.17 22.8  24.6  13.1  -2.1  13.7  NA   \n 5     5 22.7   9.66  6.77   9.78  9.74 20.2  35.9  19.2  -1.45 13.9  NA   \n 6     6 29.0  14.6  13.1   20.4  18.7  25.5  29.4  38.8   1.47 20.8  61   \n 7     7 31.4  12.1   2.42  24.9  20.6  26.5  31.8  41.2  -1.71 20.7  NA   \n 8     8 17.3   7.17  2.87  15.7   9.85 16.3  22.2  23.4   1.68 10.1  64   \n 9     9  7.75  5.69 -4.52   6.63  5.53  8.24  8.26 16.9  -5.44  5.35 -4.94\n10    10  9.33  3.00  0.677  2.96  3.42 13.4   9.70 13.7  -5.10  4.48 NA   \n11    11  7.56  3.10  3.08   3.52  2.85  9.83 13.5  16.9  -5.44  3.28  0.8 \n12    12 19.8  11.7  18.0   17.0  10.8  27.9  13.1  26.1  -3.14 12.7  NA   \n# ℹ 5 more variables: UA &lt;dbl&gt;, US &lt;dbl&gt;, VX &lt;dbl&gt;, WN &lt;dbl&gt;, YV &lt;dbl&gt;\n\n\n\nCalculate the proportion of flights that were delayed (dep_delay greater than 0) but arrived on or before time (arr_delay less than or equal to 0).\n\n\nflights %&gt;%\n  summarise(\n    proportion =\n      mean(dep_delay &gt; 0 & arr_delay &lt;= 0, na.rm = TRUE)\n  )\n\n# A tibble: 1 × 1\n  proportion\n       &lt;dbl&gt;\n1      0.108\n\n\n\nUsing the airlines and flights datasets, do the following, showing the output from each step:\n\n\nIdentify routes that more than one airline flies\n\n\nroutes_multi &lt;- flights %&gt;%\n  distinct(origin, dest, carrier) %&gt;%    # unique airline–route combos\n  count(origin, dest) %&gt;%                 # number of carriers per route\n  filter(n &gt; 1)\n\nroutes_multi\n\n# A tibble: 128 × 3\n   origin dest      n\n   &lt;chr&gt;  &lt;chr&gt; &lt;int&gt;\n 1 EWR    ATL       4\n 2 EWR    AUS       2\n 3 EWR    BDL       2\n 4 EWR    BNA       2\n 5 EWR    BOS       3\n 6 EWR    BWI       2\n 7 EWR    CHS       2\n 8 EWR    CLE       2\n 9 EWR    CLT       3\n10 EWR    CVG       2\n# ℹ 118 more rows\n\n\n\nFor each such route, calculate the average arrival delay for each airline (exclude NAs). Find the names of these airlines.\n\n\nroute_perf &lt;- flights %&gt;%\n  semi_join(routes_multi, by = c(\"origin\", \"dest\")) %&gt;% # keeps only flights on multi-airline routes\n  group_by(origin, dest, carrier) %&gt;%\n  summarise(\n    avg_arr_delay = mean(arr_delay, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %&gt;%\n  left_join(airlines, by = \"carrier\") # brings in airline names\n\nroute_perf\n\n# A tibble: 343 × 5\n   origin dest  carrier avg_arr_delay name                    \n   &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;           &lt;dbl&gt; &lt;chr&gt;                   \n 1 EWR    ATL   9E              -6.25 Endeavor Air Inc.       \n 2 EWR    ATL   DL              10.0  Delta Air Lines Inc.    \n 3 EWR    ATL   EV              19.5  ExpressJet Airlines Inc.\n 4 EWR    ATL   UA              10.5  United Air Lines Inc.   \n 5 EWR    AUS   UA               4.28 United Air Lines Inc.   \n 6 EWR    AUS   WN             -11.2  Southwest Airlines Co.  \n 7 EWR    BDL   EV               6.78 ExpressJet Airlines Inc.\n 8 EWR    BDL   UA              22.6  United Air Lines Inc.   \n 9 EWR    BNA   EV              17.7  ExpressJet Airlines Inc.\n10 EWR    BNA   WN              -2.13 Southwest Airlines Co.  \n# ℹ 333 more rows\n\n\nFor each such route, identify the airline with the worst and best average arrival delay.\n\nroute_extremes &lt;- route_perf %&gt;%\n  group_by(origin, dest) %&gt;%\n  summarise(\n    best_airline  = name[which.min(avg_arr_delay)],\n    worst_airline = name[which.max(avg_arr_delay)],\n    diff_delay    = max(avg_arr_delay) - min(avg_arr_delay),\n    .groups = \"drop\"\n  )\n\nroute_extremes\n\n# A tibble: 128 × 5\n   origin dest  best_airline             worst_airline            diff_delay\n   &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;                    &lt;chr&gt;                         &lt;dbl&gt;\n 1 EWR    ATL   Endeavor Air Inc.        ExpressJet Airlines Inc.      25.8 \n 2 EWR    AUS   Southwest Airlines Co.   United Air Lines Inc.         15.5 \n 3 EWR    BDL   ExpressJet Airlines Inc. United Air Lines Inc.         15.8 \n 4 EWR    BNA   Southwest Airlines Co.   ExpressJet Airlines Inc.      19.8 \n 5 EWR    BOS   ExpressJet Airlines Inc. JetBlue Airways               10.9 \n 6 EWR    BWI   Southwest Airlines Co.   ExpressJet Airlines Inc.      14.1 \n 7 EWR    CHS   United Air Lines Inc.    ExpressJet Airlines Inc.      30.2 \n 8 EWR    CLE   ExpressJet Airlines Inc. United Air Lines Inc.          9.68\n 9 EWR    CLT   US Airways Inc.          ExpressJet Airlines Inc.      19.6 \n10 EWR    CVG   Endeavor Air Inc.        ExpressJet Airlines Inc.      19.8 \n# ℹ 118 more rows\n\n\n\nIdentify the route with the greatest difference between the best and worst performing airlines\n\n\nroute_extremes %&gt;%\n  arrange(desc(diff_delay)) %&gt;%\n  slice(1)\n\n# A tibble: 1 × 5\n  origin dest  best_airline      worst_airline            diff_delay\n  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;             &lt;chr&gt;                         &lt;dbl&gt;\n1 JFK    ATL   Endeavor Air Inc. ExpressJet Airlines Inc.       127.\n\n\n\nDetermine the reason for this difference\n\n\nroute_perf %&gt;%\n  filter(\n    origin == route_extremes$origin[1], # possibly aircraft ype or operation effiency\n    dest   == route_extremes$dest[1]    # check scheduling buffers\n  ) %&gt;%\n  arrange(avg_arr_delay)\n\n# A tibble: 4 × 5\n  origin dest  carrier avg_arr_delay name                    \n  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;           &lt;dbl&gt; &lt;chr&gt;                   \n1 EWR    ATL   9E              -6.25 Endeavor Air Inc.       \n2 EWR    ATL   DL              10.0  Delta Air Lines Inc.    \n3 EWR    ATL   UA              10.5  United Air Lines Inc.   \n4 EWR    ATL   EV              19.5  ExpressJet Airlines Inc.\n\n\nPossible Reasons:\n\nPossible aircraft discreptencies or operation efficiency\nScheduling buffers\n\nwhich can all be observed by both origin and destinations.\n\nIdentify all columns with missing entries, typos and any other inconsistencies in the dataset below (load it just by running the code; created using dput command, FYI):\n\n\nhealth_df &lt;- structure(list(id = c(\"id_1\", \"id_2\", \"id_3\", \"id_4\", \"id_5\", \n\"id_6\", \"id_7\", \"id_8\", \"id_9\", \"id_10\", \"id_11\", \"id_12\", \"id_13\", \n\"id_14\", \"id_15\", \"id_16\", \"id_17\", \"id_18\", \"id_19\", \"id_20\", \n\"id_21\", \"id_22\", \"id_23\", \"id_24\", \"id_25\", \"id_26\", \"id_27\", \n\"id_28\", \"id_29\", \"id_30\", \"id_31\", \"id_32\", \"id_33\", \"id_34\", \n\"id_35\", \"id_36\", \"id_37\", \"id_38\", \"id_39\", \"id_40\", \"id_41\", \n\"id_42\", \"id_43\", \"id_44\", \"id_45\", \"id_46\", \"id_47\", \"id_48\", \n\"id_49\", \"id_50\"), age = c(50L, 34L, 70L, 33L, 22L, 61L, 69L, \n73L, 62L, 56L, 71L, 33L, 73L, 44L, 45L, 46L, 24L, 70L, 46L, 76L, \n47L, 76L, 28L, 48L, 54L, 27L, 45L, 26L, 61L, 28L, 38L, 55L, 33L, \n36L, 62L, 58L, 72L, 31L, 34L, 51L, 61L, 64L, 26L, 28L, 60L, 29L, \n42L, 46L, 79L, 72L), gender = c(\"male\", \"male\", \"male\", \"female\", \n\"female\", \"male\", \"female\", \"male\", \"male\", \"female\", \"female\", \n\"male\", \"male\", \"female\", \"male\", \"male\", \"male\", \"male\", \"female\", \n\"male\", \"male\", \"male\", \"male\", \"female\", \"femal\", \"male\", \"female\", \n\"female\", \"female\", \"female\", \"male\", \"female\", \"female\", \"female\", \n\"male\", \"male\", \"female\", \"male\", \"female\", \"female\", \"male\", \n\"female\", \"female\", \"male\", \"male\", \"female\", \"male\", \"male\", \n\"male\", \"female\"), height = c(174.4, 197.7, 174.1, 194.5, NA, \n180.4, 170.5, 157.4, 196.8, 165.1, 153, 197.4, 186, 157.1, 177.5, \n197.7, 179.3, 170.2, 182.4, NA, 165.4, 161, 168.5, 199.2, 157.7, \n154.6, 157.1, 184.5, 181, 194.6, 183.6, 186.9, 176.1, 183, 191.1, \n189.3, 199, 172, 165.6, 170.5, 150.5, 159.2, 192.1, 161.6, 162, \n153.8, 162.3, 186.6, 192.4, 174.9), weight = c(69.4, 62.3, 55.6, \n69.5, 78.6, 60.8, 72.2, 60.9, 75.1, 67.7, 82.5, 68.7, 67.8, 76.7, \n87, 61.1, 70.6, 63.3, 81.5, 59.2, 93.2, 87.3, 83.4, 80.9, 68.6, \n76.5, 93.7, 79.1, 92, 65.6, 85.4, 63.3, 79.7, 74.1, 63.3, 78.2, \n95.7, 95.1, 63.7, 66.1, 99.3, 81, 96.9, 73.3, 70.3, 83, 57.6, \n78.6, 61.9, 98.1), blood_type = c(\"O\", \"A\", \"O\", \"O\", \"B\", \"AB\", \n\"O\", \"O\", \"O\", \"AB\", \"A\", \"O\", \"O\", \"O\", \"B\", \"A\", \"B\", \"AB\", \n\"O\", \"AB\", \"A\", \"AB\", \"O\", \"B\", \"A\", \"A\", \"B\", \"AB\", \"A\", \"B\", \n\"B\", \"A\", \"O\", \"O\", \"O\", \"B\", \"O\", \"A\", \"A\", \"B\", \"A\", \"O\", \"AB\", \n\"A\", \"A\", \"O\", \"O\", \"B\", \"A\", \"O\"), disease_status = c(\"diseased\", \n\"healthy\", \"healthy\", \"healthy\", \"healthy\", \"healthy\", \"diseased\", \n\"healthy\", \"diseased\", \"Healthy\", \"diseased\", \"healthy\", \"diseased\", \n\"healthy\", \"diseased\", \"healthy\", \"healthy\", \"healthy\", \"healthy\", \n\"healthy\", \"healthy\", \"diseased\", \"healthy\", \"diseased\", \"healthy\", \n\"healthy\", \"healthy\", \"healthy\", \"diseased\", \"diseased\", \"healthy\", \n\"healthy\", \"healthy\", \"diseased\", \"diseased\", \"diseased\", \"healthy\", \n\"diseased\", \"healthy\", \"healthy\", \"healthy\", \"healthy\", \"healthy\", \n\"diseased\", \"diseased\", \"diseased\", \"healthy\", \"healthy\", \"diseased\", \n\"diseased\"), cholesterol = c(228, 223, 213, 198, 166, 151, 195, \n199, 189, 196, 221, 156, 185, 230, 234, 174, 185, 236, 235, 180, \n165, 220, 160, 153, 250, 153, 184, 242, 212, 179, 224, 233, 181, \n199, 220, 214, 214, 248, 191, 162, 203, 173, 199, 187, 248, 189, \n173, 212, 164, 247), glucose = c(96, 78, 101, 119, 103, 91, 86, \nNA, 77, 80, 115, 85, 88, 109, NA, 71, 90, 94, 91, 87, 113, 93, \n97, 118, 109, 80, 85, 119, 99, 108, 89, 108, 97, 116, 79, 84, \n75, 81, 119, NA, 106, 109, 75, 82, 84, 75, 76, 120, 119, 77), \n    smoker = c(\"yes\", \"yes\", \"yes\", \"yes\", \"no\", \"yes\", \"no\", \n    \"yes\", \"no\", \"no\", \"no\", \"no\", \"no\", \"yes\", \"no\", \"yes\", \n    \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"no\", \n    \"no\", \"yes\", \"yes\", \"yes\", \"no\", \"no\", \"yes\", \"no\", \"yes\", \n    \"no\", \"yes\", \"no\", \"yes\", \"yes\", \"yes\", \"no\", \"no\", \"yes\", \n    \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"yes\"), exercise = c(\"occasional\", \n    \"regular\", \"occasional\", \"regular\", \"none\", \"occasional\", \n    \"regular\", \"none\", \"occasional\", \"none\", \"occasional\", \"none\", \n    \"none\", \"regular\", \"occasional\", \"none\", \"regular\", \"regular\", \n    \"none\", \"occasional\", \"none\", \"occasional\", \"occasional\", \n    \"occasional\", \"regular\", \"occasional\", \"regular\", \"regular\", \n    \"regular\", \"occasional\", \"occasional\", \"none\", \"none\", \"regular\", \n    \"occasional\", \"occasional\", \"none\", \"none\", \"none\", \"none\", \n    \"occasional\", \"regular\", \"regular\", \"none\", \"regular\", \"occasional\", \n    \"occasional\", \"none\", \"occasional\", \"regular\"), income = c(84820L, \n    81547L, 22588L, 72490L, 74533L, 25338L, 41469L, 57315L, 63629L, \n    88662L, 62615L, 56261L, 58499L, 82232L, 77584L, 77275L, 38468L, \n    54510L, 91326L, 78611L, 31402L, 29586L, 21441L, 58269L, 84173L, \n    88295L, 37940L, 43750L, 69750L, 92356L, 82518L, 91455L, 68866L, \n    51178L, 68275L, 27689L, 35418L, 81318L, 62405L, 86851L, 25654L, \n    47553L, 74474L, 51409L, 22607L, 55360L, 96351L, 21516L, 41927L, \n    55810L), education = c(\"master\", \"bachelor\", \"PhD\", \"master\", \n    \"bachelor\", \"highschool\", \"PhD\", \"highschool\", \"PhD\", \"PhD\", \n    \"bachelor\", \"highschool\", \"master\", \"bachelor\", \"PhD\", \"PhD\", \n    \"PhD\", \"bachelor\", \"master\", \"highschool\", \"PhD\", \"highschool\", \n    \"bachelor\", \"master\", \"highschool\", \"highschool\", \"master\", \n    \"master\", \"bachelor\", \"PhD\", \"highschool\", \"PhD\", \"master\", \n    \"master\", \"master\", \"PhD\", \"highschool\", \"master\", \"master\", \n    \"highschool\", \"bachelor\", \"highschool\", \"bachelor\", \"PhD\", \n    \"bachelor\", \"highschool\", \"master\", \"highschool\", \"bachelor\", \n    \"bachelor\"), region = c(\"North\", \"South\", \"North\", \"West\", \n    \"North\", \"West\", \"South\", \"South\", \"West\", \"South\", \"West\", \n    \"South\", \"West\", \"East\", \"North\", \"West\", \"North\", \"North\", \n    \"West\", \"North\", \"East\", \"West\", \"South\", \"North\", \"North\", \n    \"East\", \"East\", \"North\", \"North\", \"West\", \"South\", \"West\", \n    \"West\", \"East\", \"West\", \"North\", \"West\", \"North\", \"East\", \n    \"North\", \"West\", \"South\", \"South\", \"East\", \"North\", \"West\", \n    \"West\", \"East\", \"North\", \"East\"), marital_status = c(\"divorced\", \n    \"single\", \"divorced\", \"divorced\", \"divorced\", \"divorced\", \n    \"divorced\", \"married\", \"divorced\", \"married\", \"divorced\", \n    \"widowed\", \"married\", \"single\", \"widowed\", \"widowed\", \"single\", \n    \"divorced\", \"widowed\", \"widowed\", \"single\", \"married\", \"single\", \n    \"married\", \"widowed\", \"married\", \"single\", \"single\", \"widowed\", \n    \"married\", \"widowed\", \"divorced\", \"single\", \"married\", \"single\", \n    \"widowed\", \"widowed\", \"married\", \"widowed\", \"divorced\", \"married\", \n    \"married\", \"divorced\", \"single\", \"married\", \"widowed\", \"divorced\", \n    \"divorced\", \"single\", \"divorced\")), row.names = c(NA, -50L\n), class = c(\"tbl_df\", \"tbl\", \"data.frame\"))\n\nData Cleaning:\n\n# check missing values\nhealth_df %&gt;%\n  summarise(across(everything(), ~ sum(is.na(.))))\n\n# A tibble: 1 × 15\n     id   age gender height weight blood_type disease_status cholesterol glucose\n  &lt;int&gt; &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;      &lt;int&gt;          &lt;int&gt;       &lt;int&gt;   &lt;int&gt;\n1     0     0      0      2      0          0              0           0       3\n# ℹ 6 more variables: smoker &lt;int&gt;, exercise &lt;int&gt;, income &lt;int&gt;,\n#   education &lt;int&gt;, region &lt;int&gt;, marital_status &lt;int&gt;\n\n# check typos e.g. \"femal\" instead of \"female\"\nhealth_df %&gt;% count(gender)\n\n# A tibble: 3 × 2\n  gender     n\n  &lt;chr&gt;  &lt;int&gt;\n1 femal      1\n2 female    22\n3 male      27\n\n# check inconsistent categories e.g. \"Healthy\" vs \"healthy\"\nhealth_df %&gt;% count(disease_status)\n\n# A tibble: 3 × 2\n  disease_status     n\n  &lt;chr&gt;          &lt;int&gt;\n1 Healthy            1\n2 diseased          19\n3 healthy           30\n\nhealth_df %&gt;% count(smoker)\n\n# A tibble: 2 × 2\n  smoker     n\n  &lt;chr&gt;  &lt;int&gt;\n1 no        23\n2 yes       27\n\nhealth_df %&gt;% count(exercise)\n\n# A tibble: 3 × 2\n  exercise       n\n  &lt;chr&gt;      &lt;int&gt;\n1 none          16\n2 occasional    19\n3 regular       15\n\n# clean up\nhealth_clean &lt;- health_df\n\n# fix typos and inconsistent categories\nhealth_clean &lt;- health_clean %&gt;%\n  mutate(\n    gender = tolower(gender),                 # avoid case mismatches\n    gender = recode(gender, femal = \"female\"),     # fix typo\n    disease_status = tolower(disease_status)  # \"Healthy\" → \"healthy\"\n  )\n\n# convert categorical variables to factors with controlled levels\nhealth_clean &lt;- health_clean %&gt;%\n  mutate(\n    gender = factor(gender, levels = c(\"male\", \"female\")),\n    smoker = factor(smoker, levels = c(\"no\", \"yes\")),\n    exercise = factor(exercise,\n                      levels = c(\"none\", \"occasional\", \"regular\")),\n    disease_status = factor(disease_status,\n                            levels = c(\"healthy\", \"diseased\")),\n    blood_type = factor(blood_type),\n    education = factor(education,\n                       levels = c(\"highschool\", \"bachelor\", \"master\", \"PhD\")),\n    marital_status = factor(marital_status),\n    region = factor(region)\n  )\n\n# check for special values\nhealth_clean &lt;- health_clean %&gt;%\n  mutate(\n    height = if_else(height &lt; 140 | height &gt; 210, NA_real_, height),\n    weight = if_else(weight &lt; 40 | weight &gt; 200, NA_real_, weight),\n    glucose = if_else(glucose &lt; 50 | glucose &gt; 300, NA_real_, glucose),\n    cholesterol = if_else(cholesterol &lt; 100 | cholesterol &gt; 400,\n                          NA_real_, cholesterol)\n  )\n\n# handle missing values\nhealth_clean &lt;- health_clean %&gt;%\n  mutate(\n    height = if_else(\n      is.na(height),\n      median(height, na.rm = TRUE),\n      height\n    ),\n    glucose = if_else(\n      is.na(glucose),\n      median(glucose, na.rm = TRUE),\n      glucose\n    )\n  )\n\n# check remaining missing values\nhealth_clean %&gt;%\n  summarise(across(everything(), ~ sum(is.na(.))))\n\n# A tibble: 1 × 15\n     id   age gender height weight blood_type disease_status cholesterol glucose\n  &lt;int&gt; &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;      &lt;int&gt;          &lt;int&gt;       &lt;int&gt;   &lt;int&gt;\n1     0     0      0      0      0          0              0           0       0\n# ℹ 6 more variables: smoker &lt;int&gt;, exercise &lt;int&gt;, income &lt;int&gt;,\n#   education &lt;int&gt;, region &lt;int&gt;, marital_status &lt;int&gt;\n\n# create derived for analysis\nhealth_clean &lt;- health_clean %&gt;%\n  mutate(\n    bmi = weight / (height / 100)^2,     # BMI in kg/m^2\n    high_cholesterol = cholesterol &gt; 240,\n    high_glucose = glucose &gt;= 126\n  )\n\n# structure check\nglimpse(health_clean)\n\nRows: 50\nColumns: 18\n$ id               &lt;chr&gt; \"id_1\", \"id_2\", \"id_3\", \"id_4\", \"id_5\", \"id_6\", \"id_7…\n$ age              &lt;int&gt; 50, 34, 70, 33, 22, 61, 69, 73, 62, 56, 71, 33, 73, 4…\n$ gender           &lt;fct&gt; male, male, male, female, female, male, female, male,…\n$ height           &lt;dbl&gt; 174.4, 197.7, 174.1, 194.5, 175.5, 180.4, 170.5, 157.…\n$ weight           &lt;dbl&gt; 69.4, 62.3, 55.6, 69.5, 78.6, 60.8, 72.2, 60.9, 75.1,…\n$ blood_type       &lt;fct&gt; O, A, O, O, B, AB, O, O, O, AB, A, O, O, O, B, A, B, …\n$ disease_status   &lt;fct&gt; diseased, healthy, healthy, healthy, healthy, healthy…\n$ cholesterol      &lt;dbl&gt; 228, 223, 213, 198, 166, 151, 195, 199, 189, 196, 221…\n$ glucose          &lt;dbl&gt; 96, 78, 101, 119, 103, 91, 86, 91, 77, 80, 115, 85, 8…\n$ smoker           &lt;fct&gt; yes, yes, yes, yes, no, yes, no, yes, no, no, no, no,…\n$ exercise         &lt;fct&gt; occasional, regular, occasional, regular, none, occas…\n$ income           &lt;int&gt; 84820, 81547, 22588, 72490, 74533, 25338, 41469, 5731…\n$ education        &lt;fct&gt; master, bachelor, PhD, master, bachelor, highschool, …\n$ region           &lt;fct&gt; North, South, North, West, North, West, South, South,…\n$ marital_status   &lt;fct&gt; divorced, single, divorced, divorced, divorced, divor…\n$ bmi              &lt;dbl&gt; 22.81742, 15.93950, 18.34329, 18.37154, 25.51927, 18.…\n$ high_cholesterol &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALS…\n$ high_glucose     &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALS…"
  },
  {
    "objectID": "Prac1.html",
    "href": "Prac1.html",
    "title": "Practical 1",
    "section": "",
    "text": "1 Questions\n\nFind all rows in airquality that have missing values. Note that the airquality dataset in R is always available (just type airquality in the console to see it).\n\n\ndata(\"airquality\") # extract data\n\nhead(airquality) # present first few rows\n\n  Ozone Solar.R Wind Temp Month Day\n1    41     190  7.4   67     5   1\n2    36     118  8.0   72     5   2\n3    12     149 12.6   74     5   3\n4    18     313 11.5   62     5   4\n5    NA      NA 14.3   56     5   5\n6    28      NA 14.9   66     5   6\n\npaste0(\" Header Names: \", names(airquality))\n\n[1] \" Header Names: Ozone\"   \" Header Names: Solar.R\" \" Header Names: Wind\"   \n[4] \" Header Names: Temp\"    \" Header Names: Month\"   \" Header Names: Day\"    \n\npaste0(\"Number of rows:\", nrow(airquality), sep = \" \")\n\n[1] \"Number of rows:153 \"\n\npaste0(\"Total number of missing values (with missing values):\", sum(is.na(airquality)), sep = \" \")\n\n[1] \"Total number of missing values (with missing values):44 \"\n\n# remove missing values\nairquality_omit &lt;- na.omit(airquality)\n\n# check missing values removed\npaste0(\"Number of rows (removing missing values): \", nrow(airquality_omit), sep = \" \")\n\n[1] \"Number of rows (removing missing values): 111 \"\n\n\n\nFind mean, sd, min, max for each of temperature and ozone level.\n\n\npaste0(\"Temperature\")\n\n[1] \"Temperature\"\n\npaste0(\" \")\n\n[1] \" \"\n\npaste0(\"sd: \", sd(airquality_omit$Temp))\n\n[1] \"sd: 9.52996910909533\"\n\npaste0(\"mean: \", mean(airquality_omit$Temp))\n\n[1] \"mean: 77.7927927927928\"\n\npaste0(\"min: \", min(airquality_omit$Temp))\n\n[1] \"min: 57\"\n\npaste0(\"max: \", max(airquality_omit$Temp))\n\n[1] \"max: 97\"\n\npaste0(\"Ozone level\")\n\n[1] \"Ozone level\"\n\npaste0(\" \")\n\n[1] \" \"\n\npaste0(\"sd: \", sd(airquality_omit$Ozone))\n\n[1] \"sd: 33.2759686574274\"\n\npaste0(\"mean: \", mean(airquality_omit$Ozone))\n\n[1] \"mean: 42.0990990990991\"\n\npaste0(\"min: \", min(airquality_omit$Ozone))\n\n[1] \"min: 1\"\n\npaste0(\"max: \", max(airquality_omit$Ozone))\n\n[1] \"max: 168\"\n\n\n\nFor linear regression, parameter estimates can be found as follows. \\[\\hat\\beta = (X^TX)^{-1}X^TY\\] Here, Y is the response variable, and X is the design matrix. The cars data (an R data set, also always available in R) contains two variables: speed and distance to stop. Fit a simple linear regression model to these data, i.e. find the estimates, using the equation above, and matrix calcuations in R.\n\n\ndata(cars) # extract dataset\n\nhead(cars) # display first few rows\n\n  speed dist\n1     4    2\n2     4   10\n3     7    4\n4     7   22\n5     8   16\n6     9   10\n\n# find Beta estimates\n\nY &lt;- cars$dist\nX &lt;- cbind(1, cars$speed)\n\nBeta_hat &lt;- solve(t(X)%*%X)%*%t(X)%*%Y\n\npaste0(\"Beta_hat: \", Beta_hat)\n\n[1] \"Beta_hat: -17.5790948905111\" \"Beta_hat: 3.93240875912409\" \n\n\n\nCheck that you get the same \\(\\beta\\) estimates as when fitting the linear regression model using lm() in R.\n\n\ncars_lm &lt;- lm(Y ~ X) # fit lm model \n\ncars_lm$coefficients\n\n(Intercept)          X1          X2 \n -17.579095          NA    3.932409"
  },
  {
    "objectID": "Day3.html",
    "href": "Day3.html",
    "title": "Day 3 Practical Question 4 & 5",
    "section": "",
    "text": "Plot the function \\(f(x) = \\sin(x)\\) for \\(x \\in [-2, 2]\\).\n\n# define the function\nf &lt;- function(x) {\n  sin(x)\n}\n\n# create a grid of x values\nx &lt;- seq(-2, 2, length.out = 400)\n\n\n# evaluate the function on the grid\ny &lt;- f(x)\n\n# plot the curve\nplot(x, y,\n     type = \"l\",        # line plot\n     lwd  = 2,\n     col  = \"blue\",\n     xlab = \"x\",\n     ylab = \"f(x) = sin(x)\",\n     main = \"Plot of f(x) = sin(x) on [-2, 2]\")\n\n# add reference line at y = 0\nabline(h = 0, lty = 2, col = \"gray\")"
  },
  {
    "objectID": "Day3.html#plot-curve-function",
    "href": "Day3.html#plot-curve-function",
    "title": "Day 3 Practical Question 4 & 5",
    "section": "",
    "text": "Plot the function \\(f(x) = \\sin(x)\\) for \\(x \\in [-2, 2]\\).\n\n# define the function\nf &lt;- function(x) {\n  sin(x)\n}\n\n# create a grid of x values\nx &lt;- seq(-2, 2, length.out = 400)\n\n\n# evaluate the function on the grid\ny &lt;- f(x)\n\n# plot the curve\nplot(x, y,\n     type = \"l\",        # line plot\n     lwd  = 2,\n     col  = \"blue\",\n     xlab = \"x\",\n     ylab = \"f(x) = sin(x)\",\n     main = \"Plot of f(x) = sin(x) on [-2, 2]\")\n\n# add reference line at y = 0\nabline(h = 0, lty = 2, col = \"gray\")"
  },
  {
    "objectID": "Day3.html#qq-plot",
    "href": "Day3.html#qq-plot",
    "title": "Day 3 Practical Question 4 & 5",
    "section": "2 QQ-plot",
    "text": "2 QQ-plot\nGenerate 1000 values from a \\(t\\)-distribution with 1 degree of freedom.\nConstruct a QQ-plot with 95% probability bands (envelopes) to check whether the above values come from a standard normal distribution. You can only use use rnorm(), but not qnorm, dnorm, pnorm, or R’s qqplot functions.\nCheck with:\n\nlibrary(car)\n\nLoading required package: carData\n\nqqPlot(x, envelope = 0.95, ylim = c(-5, 5))\n\n\n\n\n[1]   1 400\n\n\n\n# generate data from t-distribution with 1 df \nset.seed(123)\nn &lt;- 1000\n\nx &lt;- rt(n, df = 1)\n\n# sort observed data\nx_sorted &lt;- sort(x)\n\n# construct theoretical normal quantiles\n# using simulation (order statistics)\n\n# Simulate a large normal sample\nz &lt;- rnorm(n)\n\n# Sort simulated normal values\nz_sorted &lt;- sort(z)\n\n# These serve as empirical normal quantiles\ntheoretical_quantiles &lt;- z_sorted\n\n# construct 95% envelopes via Monte Carlo simulation\nB &lt;- 1000   # number of simulations\nZ_sim &lt;- matrix(NA, nrow = n, ncol = B)\n\nfor (b in 1:B) {\n  Z_sim[, b] &lt;- sort(rnorm(n))\n}\n\n# Pointwise 95% envelopes\nlower_envelope &lt;- apply(Z_sim, 1, quantile, probs = 0.025)\nupper_envelope &lt;- apply(Z_sim, 1, quantile, probs = 0.975)\n\n# QQ-plot setup\n\nplot(theoretical_quantiles, x_sorted,\n     pch = 20,\n     cex = 0.6,\n     xlab = \"Theoretical Quantiles (Normal)\",\n     ylab = \"Sample Quantiles\",\n     main = \"QQ-Plot vs Normal with 95% Envelopes\",\n     ylim = c(-5, 5))\n\n# 45-degree reference line\nabline(0, 1, col = \"blue\", lwd = 2)\n\n# Envelopes\nlines(theoretical_quantiles, lower_envelope,\n      col = \"red\", lwd = 2, lty = 2)\n\nlines(theoretical_quantiles, upper_envelope,\n      col = \"red\", lwd = 2, lty = 2)"
  }
]